{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2017fe2bed0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)    # 이렇게 하면 다음에 실행해도 같은 결과를 나오도록 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([2.5000, 4.5000, 6.5000])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([1.7, 2.9, 3.0])\n",
    "y_train = torch.FloatTensor([2.5, 19.3, 6.5])\n",
    "# y = 2*x + 0.5\n",
    "\n",
    "print(x_train, y_train, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 선언\n",
    "```py\n",
    "torch.zeros(size)   # size 크기의 텐서를 생성하고, 0으로 초기화\n",
    "\n",
    "torch.zeros(())     # 크기 없는 스칼라 -> 0\n",
    "torch.zeros((3))    # 크기 1짜리 벡터 -> [0, 0, 0]\n",
    "torch.zeros((2, 2)) # 크기 2*2짜리 행렬 -> [[0, 0], [0, 0]] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.zeros((), requires_grad=True)\n",
    "\n",
    "W"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.zeros((), requires_grad=True)\n",
    "\n",
    "b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형회귀 가설 세우기\n",
    "\n",
    "$$\n",
    "H(x) = Wx + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def H(x, weight=W, bias=b):\n",
    "    return weight * x + bias\n",
    "\n",
    "print(H(x_train[0]), H(x_train[1]), H(x_train[2]), sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용함수 선언\n",
    "\n",
    "$$\n",
    "cost(W, b) = \\frac{1}{n} \\sum_{i=1}^n (H(x_i) - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.9167, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost(W: torch.FloatTensor, b: torch.FloatTensor):\n",
    "    n = len(x_train)\n",
    "    reduce = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        reduce += (H(x_train[i], weight=W, bias=b) - y_train[i]) ** 2\n",
    "\n",
    "    return reduce / n\n",
    "    # return torch.mean((H(x_train) - y_train) ** 2)\n",
    "\n",
    "cost(W, b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사 하강법 구현\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&W := W - \\alpha \\frac{\\partial}{\\partial W} cost(W, b) \\\\\n",
    "~ \\\\\n",
    "&b := b - \\alpha \\frac{\\partial}{\\partial b} cost(W, b)  \\\\\n",
    "~ \\\\\n",
    "&(\\alpha: \\text{learning rate})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사 하강법 2000번 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/2000 W: 1.9582, b: 0.5950 Cost: 0.0012937377905473113\n",
      "Epoch  200/2000 W: 1.9875, b: 0.5283 Cost: 0.00011521808482939377\n",
      "Epoch  300/2000 W: 1.9963, b: 0.5085 Cost: 1.0261374882247765e-05\n",
      "Epoch  400/2000 W: 1.9989, b: 0.5025 Cost: 9.139667440649646e-07\n",
      "Epoch  500/2000 W: 1.9997, b: 0.5008 Cost: 8.13498317597805e-08\n",
      "Epoch  600/2000 W: 1.9999, b: 0.5002 Cost: 7.248142086524467e-09\n",
      "Epoch  700/2000 W: 2.0000, b: 0.5001 Cost: 6.483939496426672e-10\n",
      "Epoch  800/2000 W: 2.0000, b: 0.5000 Cost: 5.6559201766503975e-11\n",
      "Epoch  900/2000 W: 2.0000, b: 0.5000 Cost: 5.779080772955192e-12\n",
      "Epoch 1000/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1100/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1200/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1300/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1400/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1500/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1600/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1700/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1800/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 1900/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n",
      "Epoch 2000/2000 W: 2.0000, b: 0.5000 Cost: 1.231607372510768e-12\n"
     ]
    }
   ],
   "source": [
    "n = 2000    # epoches\n",
    "α = 0.05    # learning rate\n",
    "\n",
    "for i in range(1, n + 1):\n",
    "    grad_result = torch.autograd.grad(cost(W, b), (W, b))\n",
    "\n",
    "    W = W - α * grad_result[0]\n",
    "    b = b - α * grad_result[1]\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'Epoch {i:4d}/{n} W: {W:.4f}, b: {b:.4f} Cost: {cost(W, b)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
